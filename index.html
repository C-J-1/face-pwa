<!DOCTYPE html>
<html>
  <head>
  <title>PWA Face Detection</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf-8">
  <title>HTML5 Web App | Welcome!</title>
  <link rel="stylesheet" href="style.css">
  <link rel="manifest" href="manifest.webmanifest">
  <link rel="apple-touch-icon" sizes="57x57" href="./img/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="./img/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="./img/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="114x114" href="./img/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="./img/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="./img/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="./img/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="./img/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="./img/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="96x96" href="./img/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="./img/favicon-16x16.png">
  <link rel="manifest" href="./manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="./img/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <link rel="shortcut icon" href="./img/favicon.ico" type="image/x-icon">
  <link rel="icon" href="./img/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
  <script src="pico.js"></script>







</head>

<body>

<div class="bgimg">
  <div class="topleft">
    <p>PWA Example</p>
  </div>
  <div class="middle">
    <h2>BLEEP BLOP BLAP</h2>
    <p>Upload an image file that is 500 by 500 pixels or less...</p>
    <input type="file" onchange="onFileSelected(event)">
    <center><canvas id="canvas" height=500 width=500></canvas></center>
    <div style="display:none;"><img id="image" src="people.jpg"></div>
    <center><input type="button" value="Detect faces" onclick="button_callback()"></center>



  </div>
  <div class="bottomleft">
    <p>MadBits</p>
    <button class="add-button">Add to home screen</button>
  </div>
</div>

</body>

<script>
		/*
			download the face-detection cascade
		*/
		var facefinder_classify_region = function(r, c, s, pixels, ldim) {return -1.0;};
		var cascadeurl = './facefinder';
		fetch(cascadeurl).then(function(response) {
			response.arrayBuffer().then(function(buffer) {
				var bytes = new Int8Array(buffer);
				facefinder_classify_region = pico.unpack_cascade(bytes);
				console.log('* cascade loaded');
			})
		})
		/*
			prepare the image and canvas context
		*/
		var ctx = document.getElementById('canvas').getContext('2d');
		var img = document.getElementById('image');
		img.onload = () => ctx.drawImage(img, 0, 0);
		/*
			a function to transform an RGBA image to grayscale
		*/
		function rgba_to_grayscale(rgba, nrows, ncols) {
			var gray = new Uint8Array(nrows*ncols);
			for(var r=0; r<nrows; ++r)
				for(var c=0; c<ncols; ++c)
					// gray = 0.2*red + 0.7*green + 0.1*blue
					gray[r*ncols + c] = (2*rgba[r*4*ncols+4*c+0]+7*rgba[r*4*ncols+4*c+1]+1*rgba[r*4*ncols+4*c+2])/10;
			return gray;
		}
		/*
			this function is called each time you press the button to detect the faces
		*/
		function button_callback() {
			// re-draw the image to clear previous results and get its RGBA pixel data
			ctx.drawImage(img, 0, 0);
			var rgba = ctx.getImageData(0, 0, 500, 500).data;
			// prepare input to `run_cascade`
			image = {
				"pixels": rgba_to_grayscale(rgba, 500, 500),
				"nrows": 500,
				"ncols": 500,
				"ldim": 500
			}
			params = {
				"shiftfactor": 0.1, // move the detection window by 10% of its size
				"minsize": 50,      // minimum size of a face (not suitable for real-time detection, set it to 100 in that case)
				"maxsize": 1000,    // maximum size of a face
				"scalefactor": 1.1  // for multiscale processing: resize the detection window by 10% when moving to the higher scale
			}
			// run the cascade over the image
			// dets is an array that contains (r, c, s, q) quadruplets
			// (representing row, column, scale and detection score)
			dets = pico.run_cascade(image, facefinder_classify_region, params);
			// cluster the obtained detections
			dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
			// draw results
			qthresh = 5.0 // this constant is empirical: other cascades might require a different one
			for(i=0; i<dets.length; ++i)
				// check the detection score
				// if it's above the threshold, draw it
				if(dets[i][3]>qthresh)
				{
					ctx.beginPath();
					ctx.arc(dets[i][1], dets[i][0], dets[i][2]/2, 0, 2*Math.PI, false);
					ctx.lineWidth = 3;
					ctx.strokeStyle = 'red';
					ctx.stroke();
				}
		}
	</script>

  <script>


    function onFileSelected(event) {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    var selectedFile = event.target.files[0];
    var reader = new FileReader();

    var imgtag = document.getElementById("image");
    imgtag.title = selectedFile.name;

    reader.onload = function(event) {

      imgtag.src = event.target.result;
    };

    reader.readAsDataURL(selectedFile);
    }

  </script>

  <script src="index.js"></script>


</html>
